{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADS PRE-EXISTING NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights can be found at https://drive.google.com/drive/folders/1fn83DF14tWmit0RTKWRhPq5uVXt73e0h put into data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## load mnist dataset\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "use_cuda = False\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "pretrained_model = \"data/lenet_mnist_model.pth\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# LeNet Model definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Initialize the network\n",
    "model = Net()\n",
    "\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINS NEW NET DO NOT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# print '==>>> total trainning batch number: {}'.format(len(train_loader))\n",
    "# print '==>>> total testing batch number: {}'.format(len(test_loader))\n",
    "\n",
    "## network\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP\"\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"LeNet\"\n",
    "\n",
    "## training\n",
    "model = LeNet()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(4):\n",
    "    # trainning\n",
    "    ave_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        ave_loss = ave_loss * 0.9 + loss.data.item() * 0.1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
    "            print(\"Epoch\", epoch)\n",
    "#             print '==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx+1, ave_loss)\n",
    "    # testing\n",
    "#     correct_cnt, ave_loss = 0, 0\n",
    "#     total_cnt = 0\n",
    "#     for batch_idx, (x, target) in enumerate(test_loader):\n",
    "#         if use_cuda:\n",
    "#             x, target = x.cuda(), target.cuda()\n",
    "#         x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "#         out = model(x)\n",
    "#         loss = criterion(out, target)\n",
    "#         _, pred_label = torch.max(out.data, 1)\n",
    "#         total_cnt += x.data.size()[0]\n",
    "#         correct_cnt += (pred_label == target.data).sum()\n",
    "#         # smooth average\n",
    "#         ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n",
    "        \n",
    "#         if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "#             print(\"Epoch\", epoch)\n",
    "# #             print '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "# #                 epoch, batch_idx+1, ave_loss, correct_cnt * 1.0 / total_cnt)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "tensor(9759) 10000\n"
     ]
    }
   ],
   "source": [
    "correct_cnt, ave_loss = 0, 0\n",
    "total_cnt = 0\n",
    "epoch = 0\n",
    "for batch_idx, (x, target) in enumerate(test_loader):\n",
    "    if use_cuda:\n",
    "        x, target = x.cuda(), target.cuda()\n",
    "    x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "    out = model(x)\n",
    "    loss = criterion(out, target)\n",
    "    _, pred_label = torch.max(out.data, 1)\n",
    "    total_cnt += x.data.size()[0]\n",
    "    correct_cnt += (pred_label == target.data).sum()\n",
    "    # smooth average\n",
    "    ave_loss = ave_loss * 0.9 + loss.data.item() * 0.1\n",
    "\n",
    "    if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "        print(\"Epoch\", epoch)\n",
    "        print(correct_cnt, total_cnt)\n",
    "#             print '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "#                 epoch, batch_idx+1, ave_loss, correct_cnt * 1.0 / total_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8655, grad_fn=<MaxBackward0>) tensor(7)\n",
      "tensor(0.6084, grad_fn=<MaxBackward0>) tensor(6)\n",
      "tensor(0.8731, grad_fn=<MaxBackward0>) tensor(3)\n",
      "tensor(0.3233, grad_fn=<MaxBackward0>) tensor(4)\n",
      "tensor(0.5727, grad_fn=<MaxBackward0>) tensor(2)\n",
      "tensor(0.9881, grad_fn=<MaxBackward0>) tensor(3)\n",
      "tensor(0.8021, grad_fn=<MaxBackward0>) tensor(6)\n",
      "tensor(0.6671, grad_fn=<MaxBackward0>) tensor(1)\n",
      "tensor(0.4564, grad_fn=<MaxBackward0>) tensor(8)\n",
      "tensor(0.3371, grad_fn=<MaxBackward0>) tensor(1)\n",
      "tensor(0.7394, grad_fn=<MaxBackward0>) tensor(9)\n",
      "tensor(0.8261, grad_fn=<MaxBackward0>) tensor(7)\n",
      "tensor(0.3129, grad_fn=<MaxBackward0>) tensor(8)\n",
      "tensor(0.6217, grad_fn=<MaxBackward0>) tensor(4)\n",
      "tensor(0.7918, grad_fn=<MaxBackward0>) tensor(6)\n",
      "tensor(0.3431, grad_fn=<MaxBackward0>) tensor(3)\n",
      "tensor(0.8199, grad_fn=<MaxBackward0>) tensor(3)\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x124564f90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 17\n",
    "for counter, (img, label) in enumerate(test_loader):\n",
    "    if counter == index:\n",
    "        break\n",
    "    predict = model(img)\n",
    "    predict = torch.nn.functional.softmax(predict)\n",
    "    predict_vect, predict_label = torch.max(predict[0], 0)\n",
    "    print(predict_vect, predict_label)\n",
    "    loss = criterion(predict, label)\n",
    "    source_img = img[0, 0]\n",
    "    source_label = label[0]\n",
    "\n",
    "source_img = source_img.reshape(1, 1, 28, 28)\n",
    "source_label = source_label.reshape(1)\n",
    "print(source_img.shape)\n",
    "print(source_label.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(source_label)\n",
    "ax.imshow(source_img[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: tensor([[-1.3690, -1.1730, -0.9963,  4.3279, -1.9200,  2.4601, -2.4292, -0.8065,\n",
      "          0.3987,  0.6069]], grad_fn=<AddmmBackward>)\n",
      "Init Adv: tensor([[-1.6219, -1.2678, -1.1484,  4.6874, -1.8765,  2.5636, -2.6896, -0.8784,\n",
      "          0.4319,  0.7481]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([1, 1, 28, 28]) torch.Size([1])\n",
      "0%\n",
      "0.1539311409\n",
      "A_NL VAL: -0.0624680668116\n",
      "TIME TAKEN: 0.00508093833923\n",
      "\n",
      "0%\n",
      "0.153938293457\n",
      "A_NL VAL: -0.0624707378447\n",
      "TIME TAKEN: 0.00381517410278\n",
      "\n",
      "0%\n",
      "0.153944969177\n",
      "A_NL VAL: -0.062473423779\n",
      "TIME TAKEN: 0.00366497039795\n",
      "\n",
      "0%\n",
      "0.153952121735\n",
      "A_NL VAL: -0.0624761767685\n",
      "TIME TAKEN: 0.00410985946655\n",
      "\n",
      "0%\n",
      "0.153959274292\n",
      "A_NL VAL: -0.0624788887799\n",
      "TIME TAKEN: 0.00463604927063\n",
      "\n",
      "0%\n",
      "0.153966426849\n",
      "A_NL VAL: -0.0624816380441\n",
      "TIME TAKEN: 0.00407695770264\n",
      "\n",
      "0%\n",
      "0.15397310257\n",
      "A_NL VAL: -0.0624842531979\n",
      "TIME TAKEN: 0.00604009628296\n",
      "\n",
      "0%\n",
      "0.153980255127\n",
      "A_NL VAL: -0.0624869987369\n",
      "TIME TAKEN: 0.00395584106445\n",
      "\n",
      "0%\n",
      "0.153987407684\n",
      "A_NL VAL: -0.0624897480011\n",
      "TIME TAKEN: 0.00420689582825\n",
      "\n",
      "0%\n",
      "0.153994083405\n",
      "A_NL VAL: -0.0624923631549\n",
      "TIME TAKEN: 0.00401186943054\n",
      "\n",
      "0%\n",
      "0.154001235962\n",
      "A_NL VAL: -0.0624951347709\n",
      "TIME TAKEN: 0.00425004959106\n",
      "\n",
      "0%\n",
      "0.154008388519\n",
      "A_NL VAL: -0.0624978579581\n",
      "TIME TAKEN: 0.00427508354187\n",
      "\n",
      "0%\n",
      "0.154015541077\n",
      "A_NL VAL: -0.062500603497\n",
      "TIME TAKEN: 0.00402688980103\n",
      "\n",
      "0%\n",
      "0.154022216797\n",
      "A_NL VAL: -0.0625032112002\n",
      "TIME TAKEN: 0.00434899330139\n",
      "\n",
      "0%\n",
      "0.154029369354\n",
      "A_NL VAL: -0.0625059455633\n",
      "TIME TAKEN: 0.00437092781067\n",
      "\n",
      "0%\n",
      "0.154036521912\n",
      "A_NL VAL: -0.0625087022781\n",
      "TIME TAKEN: 0.00826001167297\n",
      "\n",
      "0%\n",
      "0.154043674469\n",
      "A_NL VAL: -0.0625114291906\n",
      "TIME TAKEN: 0.00462293624878\n",
      "\n",
      "0%\n",
      "0.154050350189\n",
      "A_NL VAL: -0.062514051795\n",
      "TIME TAKEN: 0.00357508659363\n",
      "\n",
      "0%\n",
      "0.154057502747\n",
      "A_NL VAL: -0.0625168085098\n",
      "TIME TAKEN: 0.00438499450684\n",
      "\n",
      "0%\n",
      "0.154064178467\n",
      "A_NL VAL: -0.0625194236636\n",
      "TIME TAKEN: 0.00379800796509\n",
      "\n",
      "0%\n",
      "0.154071807861\n",
      "A_NL VAL: -0.0625222921371\n",
      "TIME TAKEN: 0.00423288345337\n",
      "\n",
      "0%\n",
      "0.154078483582\n",
      "A_NL VAL: -0.0625249221921\n",
      "TIME TAKEN: 0.00414109230042\n",
      "\n",
      "0%\n",
      "0.154085636139\n",
      "A_NL VAL: -0.0625276714563\n",
      "TIME TAKEN: 0.00426697731018\n",
      "\n",
      "0%\n",
      "0.154092788696\n",
      "A_NL VAL: -0.0625304207206\n",
      "TIME TAKEN: 0.00380611419678\n",
      "\n",
      "0%\n",
      "0.154099464417\n",
      "A_NL VAL: -0.0625330135226\n",
      "TIME TAKEN: 0.00421214103699\n",
      "\n",
      "0%\n",
      "0.154106616974\n",
      "A_NL VAL: -0.0625357702374\n",
      "TIME TAKEN: 0.00586700439453\n",
      "\n",
      "0%\n",
      "0.154113769531\n",
      "A_NL VAL: -0.0625385344028\n",
      "TIME TAKEN: 0.00430297851562\n",
      "\n",
      "0%\n",
      "0.154120922089\n",
      "A_NL VAL: -0.0625412762165\n",
      "TIME TAKEN: 0.00413012504578\n",
      "\n",
      "0%\n",
      "0.154127597809\n",
      "A_NL VAL: -0.0625438690186\n",
      "TIME TAKEN: 0.00457096099854\n",
      "\n",
      "0%\n",
      "0.154134750366\n",
      "A_NL VAL: -0.062546633184\n",
      "TIME TAKEN: 0.00488090515137\n",
      "\n",
      "0%\n",
      "0.154141902924\n",
      "A_NL VAL: -0.0625493824482\n",
      "TIME TAKEN: 0.00406980514526\n",
      "\n",
      "0%\n",
      "0.154148578644\n",
      "A_NL VAL: -0.0625520125031\n",
      "TIME TAKEN: 0.00362300872803\n",
      "\n",
      "0%\n",
      "0.154156208038\n",
      "A_NL VAL: -0.0625548884273\n",
      "TIME TAKEN: 0.00360107421875\n",
      "\n",
      "0%\n",
      "0.154162883759\n",
      "A_NL VAL: -0.062557503581\n",
      "TIME TAKEN: 0.00423812866211\n",
      "\n",
      "0%\n",
      "0.154170036316\n",
      "A_NL VAL: -0.0625602304935\n",
      "TIME TAKEN: 0.00594186782837\n",
      "\n",
      "0%\n",
      "0.154176712036\n",
      "A_NL VAL: -0.0625628754497\n",
      "TIME TAKEN: 0.00382685661316\n",
      "\n",
      "0%\n",
      "0.154183864594\n",
      "A_NL VAL: -0.0625655800104\n",
      "TIME TAKEN: 0.00407886505127\n",
      "\n",
      "0%\n",
      "0.154191017151\n",
      "A_NL VAL: -0.0625683292747\n",
      "TIME TAKEN: 0.00402498245239\n",
      "\n",
      "0%\n",
      "0.154198169708\n",
      "A_NL VAL: -0.0625711008906\n",
      "TIME TAKEN: 0.00552201271057\n",
      "\n",
      "0%\n",
      "0.154205322266\n",
      "A_NL VAL: -0.0625738352537\n",
      "TIME TAKEN: 0.00463509559631\n",
      "\n",
      "0%\n",
      "0.154211997986\n",
      "A_NL VAL: -0.0625764578581\n",
      "TIME TAKEN: 0.00558614730835\n",
      "\n",
      "0%\n",
      "0.154219150543\n",
      "A_NL VAL: -0.0625792071223\n",
      "TIME TAKEN: 0.0040180683136\n",
      "\n",
      "0%\n",
      "0.154226303101\n",
      "A_NL VAL: -0.0625819414854\n",
      "TIME TAKEN: 0.00412487983704\n",
      "\n",
      "0%\n",
      "0.154232978821\n",
      "A_NL VAL: -0.0625845566392\n",
      "TIME TAKEN: 0.00394606590271\n",
      "\n",
      "0%\n",
      "0.154240131378\n",
      "A_NL VAL: -0.0625873282552\n",
      "TIME TAKEN: 0.00398802757263\n",
      "\n",
      "0%\n",
      "0.154247283936\n",
      "A_NL VAL: -0.0625900402665\n",
      "TIME TAKEN: 0.00418400764465\n",
      "\n",
      "0%\n",
      "0.154254436493\n",
      "A_NL VAL: -0.0625927895308\n",
      "TIME TAKEN: 0.00395011901855\n",
      "\n",
      "0%\n",
      "0.154261112213\n",
      "A_NL VAL: -0.0625954046845\n",
      "TIME TAKEN: 0.00539517402649\n",
      "\n",
      "0%\n",
      "0.154268264771\n",
      "A_NL VAL: -0.0625981464982\n",
      "TIME TAKEN: 0.00633716583252\n",
      "\n",
      "0%\n",
      "0.154275417328\n",
      "A_NL VAL: -0.0626009181142\n",
      "TIME TAKEN: 0.00597095489502\n",
      "\n",
      "0%\n",
      "0.154282093048\n",
      "A_NL VAL: -0.0626035407186\n",
      "TIME TAKEN: 0.00547409057617\n",
      "\n",
      "0%\n",
      "0.154289245605\n",
      "A_NL VAL: -0.0626062899828\n",
      "TIME TAKEN: 0.00495409965515\n",
      "\n",
      "0%\n",
      "0.154296398163\n",
      "A_NL VAL: -0.0626089945436\n",
      "TIME TAKEN: 0.00523591041565\n",
      "\n",
      "0%\n",
      "0.15430355072\n",
      "A_NL VAL: -0.0626117438078\n",
      "TIME TAKEN: 0.00429010391235\n",
      "\n",
      "0%\n",
      "0.15431022644\n",
      "A_NL VAL: -0.0626143664122\n",
      "TIME TAKEN: 0.00882792472839\n",
      "\n",
      "0%\n",
      "0.154317378998\n",
      "A_NL VAL: -0.0626171156764\n",
      "TIME TAKEN: 0.00544714927673\n",
      "\n",
      "0%\n",
      "0.154324531555\n",
      "A_NL VAL: -0.0626198574901\n",
      "TIME TAKEN: 0.00585389137268\n",
      "\n",
      "0%\n",
      "0.154331684113\n",
      "A_NL VAL: -0.0626225993037\n",
      "TIME TAKEN: 0.00470614433289\n",
      "\n",
      "0%\n",
      "0.154338359833\n",
      "A_NL VAL: -0.0626252293587\n",
      "TIME TAKEN: 0.00413823127747\n",
      "\n",
      "0%\n",
      "0.15434551239\n",
      "A_NL VAL: -0.0626279637218\n",
      "TIME TAKEN: 0.00606608390808\n",
      "\n",
      "0%\n",
      "0.154352664948\n",
      "A_NL VAL: -0.0626307055354\n",
      "TIME TAKEN: 0.00416707992554\n",
      "\n",
      "0%\n",
      "0.154359817505\n",
      "A_NL VAL: -0.0626334324479\n",
      "TIME TAKEN: 0.00461888313293\n",
      "\n",
      "0%\n",
      "0.154366493225\n",
      "A_NL VAL: -0.0626360476017\n",
      "TIME TAKEN: 0.00694012641907\n",
      "\n",
      "0%\n",
      "0.154373645782\n",
      "A_NL VAL: -0.0626388266683\n",
      "TIME TAKEN: 0.00465393066406\n",
      "\n",
      "0%\n",
      "0.15438079834\n",
      "A_NL VAL: -0.0626415386796\n",
      "TIME TAKEN: 0.00577402114868\n",
      "\n",
      "0%\n",
      "0.15438747406\n",
      "A_NL VAL: -0.0626441910863\n",
      "TIME TAKEN: 0.00534296035767\n",
      "\n",
      "0%\n",
      "0.154394626617\n",
      "A_NL VAL: -0.0626469254494\n",
      "TIME TAKEN: 0.00399804115295\n",
      "\n",
      "0%\n",
      "0.154401779175\n",
      "A_NL VAL: -0.0626496747136\n",
      "TIME TAKEN: 0.00434303283691\n",
      "\n",
      "0%\n",
      "0.154408931732\n",
      "A_NL VAL: -0.0626524016261\n",
      "TIME TAKEN: 0.00381588935852\n",
      "\n",
      "0%\n",
      "0.154415607452\n",
      "A_NL VAL: -0.0626550316811\n",
      "TIME TAKEN: 0.00420713424683\n",
      "\n",
      "0%\n",
      "0.15442276001\n",
      "A_NL VAL: -0.062657751143\n",
      "TIME TAKEN: 0.00387907028198\n",
      "\n",
      "0%\n",
      "0.15442943573\n",
      "A_NL VAL: -0.0626603737473\n",
      "TIME TAKEN: 0.00371384620667\n",
      "\n",
      "0%\n",
      "0.154436588287\n",
      "A_NL VAL: -0.0626631304622\n",
      "TIME TAKEN: 0.00364804267883\n",
      "\n",
      "0%\n",
      "0.154443740845\n",
      "A_NL VAL: -0.0626658648252\n",
      "TIME TAKEN: 0.00353908538818\n",
      "\n",
      "0%\n",
      "0.154450893402\n",
      "A_NL VAL: -0.0626686140895\n",
      "TIME TAKEN: 0.00414681434631\n",
      "\n",
      "0%\n",
      "0.154457569122\n",
      "A_NL VAL: -0.0626712366939\n",
      "TIME TAKEN: 0.00364899635315\n",
      "\n",
      "0%\n",
      "0.15446472168\n",
      "A_NL VAL: -0.0626739487052\n",
      "TIME TAKEN: 0.00408697128296\n",
      "\n",
      "0%\n",
      "0.154471874237\n",
      "A_NL VAL: -0.0626766905189\n",
      "TIME TAKEN: 0.00374698638916\n",
      "\n",
      "0%\n",
      "0.154478549957\n",
      "A_NL VAL: -0.0626793131232\n",
      "TIME TAKEN: 0.00385212898254\n",
      "\n",
      "0%\n",
      "0.154485702515\n",
      "A_NL VAL: -0.0626820474863\n",
      "TIME TAKEN: 0.00441098213196\n",
      "\n",
      "torch.Size([1, 1, 28, 28])\n",
      "0.86\n",
      "NEW LABEL tensor(3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'3 86.0%')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyBCE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyBCE, self).__init__()\n",
    "        \n",
    "    def forward(self, p, y):\n",
    "        return -1*(y * torch.log(p) + (1 - y) * torch.log(1 - p))\n",
    "# df_loss = DiffLoss(F.BCELoss())\n",
    "\n",
    "N = model # initialize sigmoid layer\n",
    "\n",
    "a = torch.autograd.Variable(source_img, requires_grad = True)\n",
    "y = torch.autograd.Variable(source_label, requires_grad = False)\n",
    "x = torch.autograd.Variable(torch.rand(1, 1, 28, 28)*0.3, requires_grad = True)\n",
    "# w = 1*np.array([4 , 3])\n",
    "# b = 0\n",
    "\n",
    "# w = torch.Tensor([[4, 2]])\n",
    "# b = torch.Tensor([0])\n",
    "# N.fc1.weight.data = w\n",
    "# N.fc1.bias.data = b\n",
    "\n",
    "# x = torch.autograd.Variable(torch.Tensor([0, 1]), requires_grad=True) # give some random input\n",
    "# a = torch.autograd.Variable(torch.Tensor([0., 2]), requires_grad=True) # give some random input\n",
    "# y = torch.autograd.Variable(torch.Tensor([1]), requires_grad=False) # give some random input\n",
    "\n",
    "print(\"Initial Loss:\", N(a))\n",
    "print(\"Init Adv:\", N(a + x))\n",
    "print(a.shape, y.shape)\n",
    "loss_fn = criterion\n",
    "\n",
    "# TWEAK learning rate (lr) and # of epochs (num_epochs) to generate better result\n",
    "lr = 0.01\n",
    "num_epochs = 4000\n",
    "optimizer = optim.SGD([x], lr=0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    t1 = time.time()\n",
    "    N.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "#     loss_diff.zero_grad()\n",
    "    \n",
    "    loss_adv = loss_fn(N(a + x), y)\n",
    "    loss_source = loss_fn(N(a), y)\n",
    "\n",
    "    loss_diff = torch.abs(loss_adv - loss_source) / torch.norm(x)\n",
    "    grads = grad(loss_diff, x, create_graph=True)\n",
    "    A_NL = -1*torch.norm(grads[0])\n",
    "    \n",
    "    grads = A_NL.backward()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "#         lr_val = torch.norm(grads)\n",
    "        print(str(100*(epoch // 50)*(50/num_epochs))+\"%\")\n",
    "        print(loss_adv.item())\n",
    "        print(\"A_NL VAL:\", A_NL.item())\n",
    "#         print(\"NEW LR\", np.log(1 / lr_val))\n",
    "#         print(\"GRAD VAL:\", np.log(1 / lr_val)*lr)\n",
    "        print(\"TIME TAKEN:\", time.time() - t1)\n",
    "        print()\n",
    "#     x = x - lr*grads\n",
    "    optimizer.step()\n",
    "    \n",
    "#     lr = torch.abs(5 + 4*A_NL)\n",
    "print((x + a).shape)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "result_original = torch.nn.functional.softmax(N(a)[0], dim=0)\n",
    "predict_vect_original, predict_label_original = torch.max(result_original, 0)\n",
    "predict_vect_original = round(predict_vect_original.item(), 2)\n",
    "\n",
    "result = torch.nn.functional.softmax(N(x + a)[0], dim=0)\n",
    "predict_vect, predict_label = torch.max(result, 0)\n",
    "predict_vect = round(predict_vect.item(), 2)\n",
    "\n",
    "print(predict_vect)\n",
    "print(\"NEW LABEL\", predict_label)\n",
    "print()\n",
    "ax[0].imshow((a)[0, 0].data)\n",
    "ax[1].imshow((x + a)[0, 0].data)\n",
    "ax[0].set_title(str(y.item())+\" \"+str(predict_vect_original*100)+\"%\")\n",
    "ax[1].set_title(str(predict_label.item())+\" \"+str(predict_vect*100)+\"%\")\n",
    "# model.zero_grad()\n",
    "# loss_hess.backward()\n",
    "\n",
    "# print(\"Adv Loss:\", loss_adv)\n",
    "# print(\"Source Loss:\", loss_source)\n",
    "# print(\"AL Val:\", x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
