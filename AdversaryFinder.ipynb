{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADS PRE-EXISTING NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights can be found at https://drive.google.com/drive/folders/1fn83DF14tWmit0RTKWRhPq5uVXt73e0h put into data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## load mnist dataset\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "use_cuda = False\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "pretrained_model = \"data/lenet_mnist_model.pth\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# LeNet Model definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Initialize the network\n",
    "model = Net()\n",
    "\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINS NEW NET DO NOT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# print '==>>> total trainning batch number: {}'.format(len(train_loader))\n",
    "# print '==>>> total testing batch number: {}'.format(len(test_loader))\n",
    "\n",
    "## network\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP\"\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"LeNet\"\n",
    "\n",
    "## training\n",
    "model = LeNet()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(4):\n",
    "    # trainning\n",
    "    ave_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
    "            print(\"Epoch\", epoch)\n",
    "#             print '==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx+1, ave_loss)\n",
    "    # testing\n",
    "#     correct_cnt, ave_loss = 0, 0\n",
    "#     total_cnt = 0\n",
    "#     for batch_idx, (x, target) in enumerate(test_loader):\n",
    "#         if use_cuda:\n",
    "#             x, target = x.cuda(), target.cuda()\n",
    "#         x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "#         out = model(x)\n",
    "#         loss = criterion(out, target)\n",
    "#         _, pred_label = torch.max(out.data, 1)\n",
    "#         total_cnt += x.data.size()[0]\n",
    "#         correct_cnt += (pred_label == target.data).sum()\n",
    "#         # smooth average\n",
    "#         ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n",
    "        \n",
    "#         if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "#             print(\"Epoch\", epoch)\n",
    "# #             print '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "# #                 epoch, batch_idx+1, ave_loss, correct_cnt * 1.0 / total_cnt)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "tensor(9759) 10000\n"
     ]
    }
   ],
   "source": [
    "correct_cnt, ave_loss = 0, 0\n",
    "total_cnt = 0\n",
    "epoch = 0\n",
    "for batch_idx, (x, target) in enumerate(test_loader):\n",
    "    if use_cuda:\n",
    "        x, target = x.cuda(), target.cuda()\n",
    "    x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "    out = model(x)\n",
    "    loss = criterion(out, target)\n",
    "    _, pred_label = torch.max(out.data, 1)\n",
    "    total_cnt += x.data.size()[0]\n",
    "    correct_cnt += (pred_label == target.data).sum()\n",
    "    # smooth average\n",
    "    ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n",
    "\n",
    "    if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "        print(\"Epoch\", epoch)\n",
    "        print(correct_cnt, total_cnt)\n",
    "#             print '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "#                 epoch, batch_idx+1, ave_loss, correct_cnt * 1.0 / total_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8655, grad_fn=<MaxBackward0>) tensor(7)\n",
      "tensor(0.6084, grad_fn=<MaxBackward0>) tensor(6)\n",
      "tensor(0.8731, grad_fn=<MaxBackward0>) tensor(3)\n",
      "tensor(0.3233, grad_fn=<MaxBackward0>) tensor(4)\n",
      "tensor(0.5727, grad_fn=<MaxBackward0>) tensor(2)\n",
      "tensor(0.9881, grad_fn=<MaxBackward0>) tensor(3)\n",
      "tensor(0.8021, grad_fn=<MaxBackward0>) tensor(6)\n",
      "tensor(0.6671, grad_fn=<MaxBackward0>) tensor(1)\n",
      "tensor(0.4564, grad_fn=<MaxBackward0>) tensor(8)\n",
      "tensor(0.3371, grad_fn=<MaxBackward0>) tensor(1)\n",
      "tensor(0.7394, grad_fn=<MaxBackward0>) tensor(9)\n",
      "tensor(0.8261, grad_fn=<MaxBackward0>) tensor(7)\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3077b50b38>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 17\n",
    "for counter, (img, label) in enumerate(test_loader):\n",
    "    if counter == index:\n",
    "        break\n",
    "    predict = model(img)\n",
    "    predict = torch.nn.functional.softmax(predict)\n",
    "    predict_vect, predict_label = torch.max(predict[0], 0)\n",
    "    print(predict_vect, predict_label)\n",
    "    loss = criterion(predict, label)\n",
    "    source_img = img[0, 0]\n",
    "    source_label = label[0]\n",
    "\n",
    "source_img = source_img.reshape(1, 1, 28, 28)\n",
    "source_label = source_label.reshape(1)\n",
    "print(source_img.shape)\n",
    "print(source_label.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(source_label)\n",
    "ax.imshow(source_img[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: tensor([[-2.1353, -0.6943,  0.7618,  1.1179, -0.7264, -1.6431, -5.0717,  4.1454,\n",
      "         -0.1175,  1.7752]], grad_fn=<ThAddmmBackward>)\n",
      "Init Adv: tensor([[-2.3488, -0.5350,  0.8076,  1.0117, -0.4271, -1.6726, -5.0533,  4.1765,\n",
      "         -0.0410,  1.6787]], grad_fn=<ThAddmmBackward>)\n",
      "torch.Size([1, 1, 28, 28]) torch.Size([1])\n",
      "0.0%\n",
      "0.17991113662719727\n",
      "-0.05775677412748337\n",
      "\n",
      "2.5%\n",
      "3.2283051013946533\n",
      "-0.4017198085784912\n",
      "\n",
      "5.0%\n",
      "3.1830966472625732\n",
      "-0.5776821970939636\n",
      "\n",
      "7.5%\n",
      "2.4471683502197266\n",
      "-1.1259485483169556\n",
      "\n",
      "10.0%\n",
      "2.362769842147827\n",
      "-0.9469200968742371\n",
      "\n",
      "12.5%\n",
      "2.257607936859131\n",
      "-1.0762927532196045\n",
      "\n",
      "15.0%\n",
      "2.5045814514160156\n",
      "-0.9552426338195801\n",
      "\n",
      "17.5%\n",
      "2.3210835456848145\n",
      "-0.9459443092346191\n",
      "\n",
      "20.0%\n",
      "2.2891685962677\n",
      "-1.062844157218933\n",
      "\n",
      "22.5%\n",
      "2.3281912803649902\n",
      "-0.9468343257904053\n",
      "\n",
      "25.0%\n",
      "2.3418757915496826\n",
      "-0.9620873332023621\n",
      "\n",
      "27.5%\n",
      "2.4141294956207275\n",
      "-0.9287999868392944\n",
      "\n",
      "30.0%\n",
      "2.3055121898651123\n",
      "-1.053961992263794\n",
      "\n",
      "32.5%\n",
      "2.317103862762451\n",
      "-0.9359727501869202\n",
      "\n",
      "35.0%\n",
      "2.266439437866211\n",
      "-1.1346063613891602\n",
      "\n",
      "37.5%\n",
      "2.366360902786255\n",
      "-0.9286926984786987\n",
      "\n",
      "40.0%\n",
      "2.32928466796875\n",
      "-0.9553214311599731\n",
      "\n",
      "42.5%\n",
      "2.43442964553833\n",
      "-0.9108858108520508\n",
      "\n",
      "45.0%\n",
      "2.234193801879883\n",
      "-1.1822446584701538\n",
      "\n",
      "47.5%\n",
      "2.331674098968506\n",
      "-0.9327113032341003\n",
      "\n",
      "50.0%\n",
      "2.4311938285827637\n",
      "-0.9284008145332336\n",
      "\n",
      "52.5%\n",
      "2.3593950271606445\n",
      "-0.8971323370933533\n",
      "\n",
      "55.0%\n",
      "2.5164639949798584\n",
      "-0.941874086856842\n",
      "\n",
      "57.5%\n",
      "2.2708921432495117\n",
      "-1.0300101041793823\n",
      "\n",
      "60.0%\n",
      "2.310828685760498\n",
      "-0.942875325679779\n",
      "\n",
      "62.5%\n",
      "2.4590635299682617\n",
      "-0.8886473774909973\n",
      "\n",
      "65.0%\n",
      "2.4050750732421875\n",
      "-0.8913764953613281\n",
      "\n",
      "67.5%\n",
      "2.438537120819092\n",
      "-0.8834466338157654\n",
      "\n",
      "70.0%\n",
      "2.2486119270324707\n",
      "-1.0769838094711304\n",
      "\n",
      "72.5%\n",
      "2.3666653633117676\n",
      "-0.9087353944778442\n",
      "\n",
      "75.0%\n",
      "2.247514486312866\n",
      "-1.0480408668518066\n",
      "\n",
      "77.5%\n",
      "2.238168716430664\n",
      "-1.1962285041809082\n",
      "\n",
      "80.0%\n",
      "2.38214111328125\n",
      "-0.9261506199836731\n",
      "\n",
      "82.5%\n",
      "2.4295687675476074\n",
      "-0.9185914993286133\n",
      "\n",
      "85.0%\n",
      "2.2559280395507812\n",
      "-1.043310284614563\n",
      "\n",
      "87.5%\n",
      "2.4627814292907715\n",
      "-0.9552400708198547\n",
      "\n",
      "90.0%\n",
      "2.436060667037964\n",
      "-0.9183183908462524\n",
      "\n",
      "92.5%\n",
      "2.2793922424316406\n",
      "-1.040047287940979\n",
      "\n",
      "95.0%\n",
      "2.2788546085357666\n",
      "-1.025375485420227\n",
      "\n",
      "97.5%\n",
      "2.271170139312744\n",
      "-1.0511451959609985\n",
      "\n",
      "torch.Size([1, 1, 28, 28])\n",
      "0.38\n",
      "NEW LABEL tensor(5)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'5 38.0%')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyBCE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyBCE, self).__init__()\n",
    "        \n",
    "    def forward(self, p, y):\n",
    "        return -1*(y * torch.log(p) + (1 - y) * torch.log(1 - p))\n",
    "# df_loss = DiffLoss(F.BCELoss())\n",
    "\n",
    "N = model # initialize sigmoid layer\n",
    "\n",
    "a = torch.autograd.Variable(source_img, requires_grad = True)\n",
    "y = torch.autograd.Variable(source_label, requires_grad = False)\n",
    "x = torch.autograd.Variable(torch.rand(1, 1, 28, 28)*0.3, requires_grad = True)\n",
    "# w = 1*np.array([4 , 3])\n",
    "# b = 0\n",
    "\n",
    "# w = torch.Tensor([[4, 2]])\n",
    "# b = torch.Tensor([0])\n",
    "# N.fc1.weight.data = w\n",
    "# N.fc1.bias.data = b\n",
    "\n",
    "# x = torch.autograd.Variable(torch.Tensor([0, 1]), requires_grad=True) # give some random input\n",
    "# a = torch.autograd.Variable(torch.Tensor([0., 2]), requires_grad=True) # give some random input\n",
    "# y = torch.autograd.Variable(torch.Tensor([1]), requires_grad=False) # give some random input\n",
    "\n",
    "print(\"Initial Loss:\", N(a))\n",
    "print(\"Init Adv:\", N(a + x))\n",
    "print(a.shape, y.shape)\n",
    "loss_fn = criterion\n",
    "\n",
    "# TWEAK learning rate (lr) and # of epochs (num_epochs) to generate better result\n",
    "lr = 0.01\n",
    "num_epochs = 4000\n",
    "optimizer = optim.SGD([x], lr=0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    t1 = time.time()\n",
    "    N.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "#     loss_diff.zero_grad()\n",
    "    \n",
    "    loss_adv = loss_fn(N(a + x), y)\n",
    "    loss_source = loss_fn(N(a), y)\n",
    "\n",
    "    loss_diff = torch.abs(loss_adv - loss_source) / torch.norm(x)\n",
    "    grads = grad(loss_diff, x, create_graph=True)\n",
    "    A_NL = -1*torch.norm(grads[0])\n",
    "    \n",
    "    grads = A_NL.backward()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "#         lr_val = torch.norm(grads)\n",
    "        print(str(100*(epoch // 50)*(50/num_epochs))+\"%\")\n",
    "        print(loss_adv.item())\n",
    "        print(\"A_NL VAL:\", A_NL.item())\n",
    "#         print(\"NEW LR\", np.log(1 / lr_val))\n",
    "#         print(\"GRAD VAL:\", np.log(1 / lr_val)*lr)\n",
    "        print(\"TIME TAKEN:\", time.time() - t1)\n",
    "        print()\n",
    "#     x = x - lr*grads\n",
    "    optimizer.step()\n",
    "    \n",
    "#     lr = torch.abs(5 + 4*A_NL)\n",
    "print((x + a).shape)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "result_original = torch.nn.functional.softmax(N(a)[0])\n",
    "predict_vect_original, predict_label_original = torch.max(result_original, 0)\n",
    "predict_vect_original = round(predict_vect_original.item(), 2)\n",
    "\n",
    "result = torch.nn.functional.softmax(N(x + a)[0])\n",
    "predict_vect, predict_label = torch.max(result, 0)\n",
    "predict_vect = round(predict_vect.item(), 2)\n",
    "\n",
    "print(predict_vect)\n",
    "print(\"NEW LABEL\", predict_label)\n",
    "print()\n",
    "ax[0].imshow((a)[0, 0].data)\n",
    "ax[1].imshow((x + a)[0, 0].data)\n",
    "ax[0].set_title(str(y.item())+\" \"+str(predict_vect_original*100)+\"%\")\n",
    "ax[1].set_title(str(predict_label.item())+\" \"+str(predict_vect*100)+\"%\")\n",
    "# model.zero_grad()\n",
    "# loss_hess.backward()\n",
    "\n",
    "# print(\"Adv Loss:\", loss_adv)\n",
    "# print(\"Source Loss:\", loss_source)\n",
    "# print(\"AL Val:\", x.grad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
