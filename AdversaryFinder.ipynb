{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADS PRE-EXISTING NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights can be found at https://drive.google.com/drive/folders/1fn83DF14tWmit0RTKWRhPq5uVXt73e0h put into data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## load mnist dataset\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "use_cuda = False\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "pretrained_model = \"data/lenet_mnist_model.pth\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# LeNet Model definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Initialize the network\n",
    "model = Net()\n",
    "\n",
    "# Load the pretrained model\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINS NEW NET DO NOT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "Epoch 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# print '==>>> total trainning batch number: {}'.format(len(train_loader))\n",
    "# print '==>>> total testing batch number: {}'.format(len(test_loader))\n",
    "\n",
    "## network\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP\"\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"LeNet\"\n",
    "\n",
    "## training\n",
    "model = LeNet()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(4):\n",
    "    # trainning\n",
    "    ave_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        ave_loss = ave_loss * 0.9 + loss.data.item() * 0.1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
    "            print(\"Epoch\", epoch)\n",
    "#             print '==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx+1, ave_loss)\n",
    "    # testing\n",
    "#     correct_cnt, ave_loss = 0, 0\n",
    "#     total_cnt = 0\n",
    "#     for batch_idx, (x, target) in enumerate(test_loader):\n",
    "#         if use_cuda:\n",
    "#             x, target = x.cuda(), target.cuda()\n",
    "#         x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "#         out = model(x)\n",
    "#         loss = criterion(out, target)\n",
    "#         _, pred_label = torch.max(out.data, 1)\n",
    "#         total_cnt += x.data.size()[0]\n",
    "#         correct_cnt += (pred_label == target.data).sum()\n",
    "#         # smooth average\n",
    "#         ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n",
    "        \n",
    "#         if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "#             print(\"Epoch\", epoch)\n",
    "# #             print '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "# #                 epoch, batch_idx+1, ave_loss, correct_cnt * 1.0 / total_cnt)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "tensor(9759) 10000\n"
     ]
    }
   ],
   "source": [
    "correct_cnt, ave_loss = 0, 0\n",
    "total_cnt = 0\n",
    "epoch = 0\n",
    "for batch_idx, (x, target) in enumerate(test_loader):\n",
    "    if use_cuda:\n",
    "        x, target = x.cuda(), target.cuda()\n",
    "    x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "    out = model(x)\n",
    "    loss = criterion(out, target)\n",
    "    _, pred_label = torch.max(out.data, 1)\n",
    "    total_cnt += x.data.size()[0]\n",
    "    correct_cnt += (pred_label == target.data).sum()\n",
    "    # smooth average\n",
    "    ave_loss = ave_loss * 0.9 + loss.data.item() * 0.1\n",
    "\n",
    "    if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "        print(\"Epoch\", epoch)\n",
    "        print(correct_cnt, total_cnt)\n",
    "#             print '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
    "#                 epoch, batch_idx+1, ave_loss, correct_cnt * 1.0 / total_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8655, grad_fn=<MaxBackward0>) tensor(7)\n",
      "tensor(0.6084, grad_fn=<MaxBackward0>) tensor(6)\n",
      "tensor(0.8731, grad_fn=<MaxBackward0>) tensor(3)\n",
      "tensor(0.3233, grad_fn=<MaxBackward0>) tensor(4)\n",
      "tensor(0.5727, grad_fn=<MaxBackward0>) tensor(2)\n",
      "tensor(0.9881, grad_fn=<MaxBackward0>) tensor(3)\n",
      "tensor(0.8021, grad_fn=<MaxBackward0>) tensor(6)\n",
      "tensor(0.6671, grad_fn=<MaxBackward0>) tensor(1)\n",
      "tensor(0.4564, grad_fn=<MaxBackward0>) tensor(8)\n",
      "tensor(0.3371, grad_fn=<MaxBackward0>) tensor(1)\n",
      "tensor(0.7394, grad_fn=<MaxBackward0>) tensor(9)\n",
      "tensor(0.8261, grad_fn=<MaxBackward0>) tensor(7)\n",
      "tensor(0.3129, grad_fn=<MaxBackward0>) tensor(8)\n",
      "tensor(0.6217, grad_fn=<MaxBackward0>) tensor(4)\n",
      "tensor(0.7918, grad_fn=<MaxBackward0>) tensor(6)\n",
      "tensor(0.3431, grad_fn=<MaxBackward0>) tensor(3)\n",
      "tensor(0.8199, grad_fn=<MaxBackward0>) tensor(3)\n",
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb021c911d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 17\n",
    "for counter, (img, label) in enumerate(test_loader):\n",
    "    if counter == index:\n",
    "        break\n",
    "    predict = model(img)\n",
    "    predict = torch.nn.functional.softmax(predict)\n",
    "    predict_vect, predict_label = torch.max(predict[0], 0)\n",
    "    print(predict_vect, predict_label)\n",
    "    loss = criterion(predict, label)\n",
    "    source_img = img[0, 0]\n",
    "    source_label = label[0]\n",
    "\n",
    "source_img = source_img.reshape(1, 1, 28, 28)\n",
    "source_label = source_label.reshape(1)\n",
    "print(source_img.shape)\n",
    "print(source_label.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(source_label)\n",
    "ax.imshow(source_img[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: tensor([[-1.3690, -1.1730, -0.9963,  4.3279, -1.9200,  2.4601, -2.4292, -0.8065,\n",
      "          0.3987,  0.6069]], grad_fn=<ThAddmmBackward>)\n",
      "Init Adv: tensor([[-1.5082, -1.4389, -1.4346,  4.5284, -1.8185,  2.9503, -2.4319, -1.0878,\n",
      "          0.5954,  0.9239]], grad_fn=<ThAddmmBackward>)\n",
      "torch.Size([1, 1, 28, 28]) torch.Size([1])\n",
      "0.0%\n",
      "0.23666810989379883\n",
      "A_NL VAL: -0.11031229048967361\n",
      "TIME TAKEN: 0.010431289672851562\n",
      "\n",
      "1.25%\n",
      "0.24251604080200195\n",
      "A_NL VAL: -0.11284269392490387\n",
      "TIME TAKEN: 0.0049152374267578125\n",
      "\n",
      "2.5%\n",
      "0.24860000610351562\n",
      "A_NL VAL: -0.11547385901212692\n",
      "TIME TAKEN: 0.00471806526184082\n",
      "\n",
      "3.75%\n",
      "0.2549309730529785\n",
      "A_NL VAL: -0.1181730255484581\n",
      "TIME TAKEN: 0.0037431716918945312\n",
      "\n",
      "5.0%\n",
      "0.2615175247192383\n",
      "A_NL VAL: -0.12096373736858368\n",
      "TIME TAKEN: 0.007585287094116211\n",
      "\n",
      "6.25%\n",
      "0.2683892250061035\n",
      "A_NL VAL: -0.12390315532684326\n",
      "TIME TAKEN: 0.004135608673095703\n",
      "\n",
      "7.5%\n",
      "0.2755413055419922\n",
      "A_NL VAL: -0.12699423730373383\n",
      "TIME TAKEN: 0.003490924835205078\n",
      "\n",
      "8.75%\n",
      "0.28293609619140625\n",
      "A_NL VAL: -0.12719258666038513\n",
      "TIME TAKEN: 0.0035703182220458984\n",
      "\n",
      "10.0%\n",
      "0.290377140045166\n",
      "A_NL VAL: -0.13059771060943604\n",
      "TIME TAKEN: 0.003720521926879883\n",
      "\n",
      "11.25%\n",
      "0.29799699783325195\n",
      "A_NL VAL: -0.13412413001060486\n",
      "TIME TAKEN: 0.01031351089477539\n",
      "\n",
      "12.5%\n",
      "0.30591297149658203\n",
      "A_NL VAL: -0.13721808791160583\n",
      "TIME TAKEN: 0.006623029708862305\n",
      "\n",
      "13.75%\n",
      "0.3146352767944336\n",
      "A_NL VAL: -0.15267673134803772\n",
      "TIME TAKEN: 0.0046694278717041016\n",
      "\n",
      "15.0%\n",
      "0.3256368637084961\n",
      "A_NL VAL: -0.1573410928249359\n",
      "TIME TAKEN: 0.004337310791015625\n",
      "\n",
      "16.25%\n",
      "0.33718395233154297\n",
      "A_NL VAL: -0.16212716698646545\n",
      "TIME TAKEN: 0.0066509246826171875\n",
      "\n",
      "17.5%\n",
      "0.3493008613586426\n",
      "A_NL VAL: -0.16715559363365173\n",
      "TIME TAKEN: 0.02887558937072754\n",
      "\n",
      "18.75%\n",
      "0.3620142936706543\n",
      "A_NL VAL: -0.1722983568906784\n",
      "TIME TAKEN: 0.007066011428833008\n",
      "\n",
      "20.0%\n",
      "0.37534046173095703\n",
      "A_NL VAL: -0.17939896881580353\n",
      "TIME TAKEN: 0.004915714263916016\n",
      "\n",
      "21.25%\n",
      "0.39093637466430664\n",
      "A_NL VAL: -0.19647032022476196\n",
      "TIME TAKEN: 0.006633281707763672\n",
      "\n",
      "22.5%\n",
      "0.40912628173828125\n",
      "A_NL VAL: -0.20386211574077606\n",
      "TIME TAKEN: 0.018422603607177734\n",
      "\n",
      "23.75%\n",
      "0.42835187911987305\n",
      "A_NL VAL: -0.21126484870910645\n",
      "TIME TAKEN: 0.009157180786132812\n",
      "\n",
      "25.0%\n",
      "0.4485139846801758\n",
      "A_NL VAL: -0.21925437450408936\n",
      "TIME TAKEN: 0.003722667694091797\n",
      "\n",
      "26.25%\n",
      "0.46946048736572266\n",
      "A_NL VAL: -0.22624295949935913\n",
      "TIME TAKEN: 0.003400564193725586\n",
      "\n",
      "27.5%\n",
      "0.4912538528442383\n",
      "A_NL VAL: -0.2325885146856308\n",
      "TIME TAKEN: 0.003909587860107422\n",
      "\n",
      "28.75%\n",
      "0.513676643371582\n",
      "A_NL VAL: -0.2405041754245758\n",
      "TIME TAKEN: 0.007281780242919922\n",
      "\n",
      "30.0%\n",
      "0.536139965057373\n",
      "A_NL VAL: -0.2423676997423172\n",
      "TIME TAKEN: 0.015346765518188477\n",
      "\n",
      "31.25%\n",
      "0.5616466999053955\n",
      "A_NL VAL: -0.2682781219482422\n",
      "TIME TAKEN: 0.003942012786865234\n",
      "\n",
      "32.5%\n",
      "0.5906364917755127\n",
      "A_NL VAL: -0.2785901129245758\n",
      "TIME TAKEN: 0.006201982498168945\n",
      "\n",
      "33.75%\n",
      "0.620959997177124\n",
      "A_NL VAL: -0.2892141342163086\n",
      "TIME TAKEN: 0.003634929656982422\n",
      "\n",
      "35.0%\n",
      "0.6517913341522217\n",
      "A_NL VAL: -0.29551494121551514\n",
      "TIME TAKEN: 0.010553359985351562\n",
      "\n",
      "36.25%\n",
      "0.678839921951294\n",
      "A_NL VAL: -0.2776293158531189\n",
      "TIME TAKEN: 0.004345417022705078\n",
      "\n",
      "37.5%\n",
      "0.7038781642913818\n",
      "A_NL VAL: -0.2920248508453369\n",
      "TIME TAKEN: 0.007712841033935547\n",
      "\n",
      "38.75%\n",
      "0.7312495708465576\n",
      "A_NL VAL: -0.2988077700138092\n",
      "TIME TAKEN: 0.0048410892486572266\n",
      "\n",
      "40.0%\n",
      "0.7580530643463135\n",
      "A_NL VAL: -0.30108359456062317\n",
      "TIME TAKEN: 0.006867408752441406\n",
      "\n",
      "41.25%\n",
      "0.7850406169891357\n",
      "A_NL VAL: -0.30833640694618225\n",
      "TIME TAKEN: 0.007492780685424805\n",
      "\n",
      "42.5%\n",
      "0.8119101524353027\n",
      "A_NL VAL: -0.3134692311286926\n",
      "TIME TAKEN: 0.005173921585083008\n",
      "\n",
      "43.75%\n",
      "0.8391807079315186\n",
      "A_NL VAL: -0.3192162811756134\n",
      "TIME TAKEN: 0.007053852081298828\n",
      "\n",
      "45.0%\n",
      "0.8664186000823975\n",
      "A_NL VAL: -0.32522186636924744\n",
      "TIME TAKEN: 0.003814697265625\n",
      "\n",
      "46.25%\n",
      "0.8939235210418701\n",
      "A_NL VAL: -0.33166271448135376\n",
      "TIME TAKEN: 0.0039975643157958984\n",
      "\n",
      "47.5%\n",
      "0.9217042922973633\n",
      "A_NL VAL: -0.33776187896728516\n",
      "TIME TAKEN: 0.003543853759765625\n",
      "\n",
      "48.75%\n",
      "0.9497106075286865\n",
      "A_NL VAL: -0.34350332617759705\n",
      "TIME TAKEN: 0.0051364898681640625\n",
      "\n",
      "50.0%\n",
      "0.9777207374572754\n",
      "A_NL VAL: -0.3495166301727295\n",
      "TIME TAKEN: 0.00499725341796875\n",
      "\n",
      "51.25%\n",
      "1.0052192211151123\n",
      "A_NL VAL: -0.352160781621933\n",
      "TIME TAKEN: 0.014342546463012695\n",
      "\n",
      "52.5%\n",
      "1.03269624710083\n",
      "A_NL VAL: -0.35738450288772583\n",
      "TIME TAKEN: 0.0042667388916015625\n",
      "\n",
      "53.75%\n",
      "1.0575568675994873\n",
      "A_NL VAL: -0.3170625567436218\n",
      "TIME TAKEN: 0.0042073726654052734\n",
      "\n",
      "55.0%\n",
      "1.0760245323181152\n",
      "A_NL VAL: -0.3171237111091614\n",
      "TIME TAKEN: 0.0045430660247802734\n",
      "\n",
      "56.25%\n",
      "1.0942885875701904\n",
      "A_NL VAL: -0.32455092668533325\n",
      "TIME TAKEN: 0.008327245712280273\n",
      "\n",
      "57.5%\n",
      "1.1111986637115479\n",
      "A_NL VAL: -0.30662786960601807\n",
      "TIME TAKEN: 0.006704807281494141\n",
      "\n",
      "58.75%\n",
      "1.1263935565948486\n",
      "A_NL VAL: -0.3281826674938202\n",
      "TIME TAKEN: 0.021185636520385742\n",
      "\n",
      "60.0%\n",
      "1.1446707248687744\n",
      "A_NL VAL: -0.3306412398815155\n",
      "TIME TAKEN: 0.0042726993560791016\n",
      "\n",
      "61.25%\n",
      "1.1628386974334717\n",
      "A_NL VAL: -0.3332032561302185\n",
      "TIME TAKEN: 0.007069826126098633\n",
      "\n",
      "62.5%\n",
      "1.1809492111206055\n",
      "A_NL VAL: -0.3363715410232544\n",
      "TIME TAKEN: 0.01118326187133789\n",
      "\n",
      "63.75%\n",
      "1.198822259902954\n",
      "A_NL VAL: -0.33754897117614746\n",
      "TIME TAKEN: 0.009818792343139648\n",
      "\n",
      "65.0%\n",
      "1.2174723148345947\n",
      "A_NL VAL: -0.3463013768196106\n",
      "TIME TAKEN: 0.005230426788330078\n",
      "\n",
      "66.25%\n",
      "1.236076831817627\n",
      "A_NL VAL: -0.34906959533691406\n",
      "TIME TAKEN: 0.006031513214111328\n",
      "\n",
      "67.5%\n",
      "1.2546494007110596\n",
      "A_NL VAL: -0.3525288701057434\n",
      "TIME TAKEN: 0.0050427913665771484\n",
      "\n",
      "68.75%\n",
      "1.273144006729126\n",
      "A_NL VAL: -0.3553292155265808\n",
      "TIME TAKEN: 0.012032508850097656\n",
      "\n",
      "70.0%\n",
      "1.2912302017211914\n",
      "A_NL VAL: -0.3558768630027771\n",
      "TIME TAKEN: 0.003650665283203125\n",
      "\n",
      "71.25%\n",
      "1.309645175933838\n",
      "A_NL VAL: -0.36207467317581177\n",
      "TIME TAKEN: 0.00959324836730957\n",
      "\n",
      "72.5%\n",
      "1.3280274868011475\n",
      "A_NL VAL: -0.3650626540184021\n",
      "TIME TAKEN: 0.008800983428955078\n",
      "\n",
      "73.75%\n",
      "1.343397855758667\n",
      "A_NL VAL: -0.33948445320129395\n",
      "TIME TAKEN: 0.0077097415924072266\n",
      "\n",
      "75.0%\n",
      "1.3573737144470215\n",
      "A_NL VAL: -0.34048697352409363\n",
      "TIME TAKEN: 0.010040760040283203\n",
      "\n",
      "76.25%\n",
      "1.3712480068206787\n",
      "A_NL VAL: -0.3419772982597351\n",
      "TIME TAKEN: 0.005259275436401367\n",
      "\n",
      "77.5%\n",
      "1.385009765625\n",
      "A_NL VAL: -0.34508201479911804\n",
      "TIME TAKEN: 0.0033702850341796875\n",
      "\n",
      "78.75%\n",
      "1.3989794254302979\n",
      "A_NL VAL: -0.3488937318325043\n",
      "TIME TAKEN: 0.006873130798339844\n",
      "\n",
      "80.0%\n",
      "1.4129977226257324\n",
      "A_NL VAL: -0.3498672544956207\n",
      "TIME TAKEN: 0.004524707794189453\n",
      "\n",
      "81.25%\n",
      "1.4269163608551025\n",
      "A_NL VAL: -0.3521025776863098\n",
      "TIME TAKEN: 0.004164218902587891\n",
      "\n",
      "82.5%\n",
      "1.4407122135162354\n",
      "A_NL VAL: -0.3537137806415558\n",
      "TIME TAKEN: 0.0046617984771728516\n",
      "\n",
      "83.75%\n",
      "1.4524977207183838\n",
      "A_NL VAL: -0.33617934584617615\n",
      "TIME TAKEN: 0.0038552284240722656\n",
      "\n",
      "85.0%\n",
      "1.4641087055206299\n",
      "A_NL VAL: -0.33739662170410156\n",
      "TIME TAKEN: 0.003604888916015625\n",
      "\n",
      "86.25%\n",
      "1.4756343364715576\n",
      "A_NL VAL: -0.33905261754989624\n",
      "TIME TAKEN: 0.0036253929138183594\n",
      "\n",
      "87.5%\n",
      "1.4870412349700928\n",
      "A_NL VAL: -0.3395445942878723\n",
      "TIME TAKEN: 0.0038297176361083984\n",
      "\n",
      "88.75%\n",
      "1.4983370304107666\n",
      "A_NL VAL: -0.3412010967731476\n",
      "TIME TAKEN: 0.004389047622680664\n",
      "\n",
      "90.0%\n",
      "1.509552240371704\n",
      "A_NL VAL: -0.3421696722507477\n",
      "TIME TAKEN: 0.0042726993560791016\n",
      "\n",
      "91.25%\n",
      "1.5206801891326904\n",
      "A_NL VAL: -0.3450612723827362\n",
      "TIME TAKEN: 0.004842996597290039\n",
      "\n",
      "92.5%\n",
      "1.5317261219024658\n",
      "A_NL VAL: -0.3443591594696045\n",
      "TIME TAKEN: 0.004384279251098633\n",
      "\n",
      "93.75%\n",
      "1.5426571369171143\n",
      "A_NL VAL: -0.341300368309021\n",
      "TIME TAKEN: 0.012337684631347656\n",
      "\n",
      "95.0%\n",
      "1.5529019832611084\n",
      "A_NL VAL: -0.3398919701576233\n",
      "TIME TAKEN: 0.003979921340942383\n",
      "\n",
      "96.25%\n",
      "1.5629873275756836\n",
      "A_NL VAL: -0.3409271836280823\n",
      "TIME TAKEN: 0.014191865921020508\n",
      "\n",
      "97.5%\n",
      "1.5728857517242432\n",
      "A_NL VAL: -0.3421814739704132\n",
      "TIME TAKEN: 0.003464221954345703\n",
      "\n",
      "98.75%\n",
      "1.5826857089996338\n",
      "A_NL VAL: -0.34662294387817383\n",
      "TIME TAKEN: 0.00464630126953125\n",
      "\n",
      "torch.Size([1, 1, 28, 28])\n",
      "0.71\n",
      "NEW LABEL tensor(5)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'5 71.0%')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyBCE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyBCE, self).__init__()\n",
    "        \n",
    "    def forward(self, p, y):\n",
    "        return -1*(y * torch.log(p) + (1 - y) * torch.log(1 - p))\n",
    "# df_loss = DiffLoss(F.BCELoss())\n",
    "\n",
    "N = model # initialize sigmoid layer\n",
    "\n",
    "a = torch.autograd.Variable(source_img, requires_grad = True)\n",
    "y = torch.autograd.Variable(source_label, requires_grad = False)\n",
    "x = torch.autograd.Variable(torch.rand(1, 1, 28, 28)*0.3, requires_grad = True)\n",
    "# w = 1*np.array([4 , 3])\n",
    "# b = 0\n",
    "\n",
    "# w = torch.Tensor([[4, 2]])\n",
    "# b = torch.Tensor([0])\n",
    "# N.fc1.weight.data = w\n",
    "# N.fc1.bias.data = b\n",
    "\n",
    "# x = torch.autograd.Variable(torch.Tensor([0, 1]), requires_grad=True) # give some random input\n",
    "# a = torch.autograd.Variable(torch.Tensor([0., 2]), requires_grad=True) # give some random input\n",
    "# y = torch.autograd.Variable(torch.Tensor([1]), requires_grad=False) # give some random input\n",
    "\n",
    "print(\"Initial Loss:\", N(a))\n",
    "print(\"Init Adv:\", N(a + x))\n",
    "print(a.shape, y.shape)\n",
    "loss_fn = criterion\n",
    "\n",
    "# TWEAK learning rate (lr) and # of epochs (num_epochs) to generate better result\n",
    "lr = 0.01\n",
    "num_epochs = 4000\n",
    "optimizer = optim.SGD([x], lr=0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    t1 = time.time()\n",
    "    N.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "#     loss_diff.zero_grad()\n",
    "    \n",
    "    loss_adv = loss_fn(N(a + x), y)\n",
    "    loss_source = loss_fn(N(a), y)\n",
    "\n",
    "    loss_diff = torch.abs(loss_adv - loss_source) / torch.norm(x)\n",
    "    grads = grad(loss_diff, x, create_graph=True)\n",
    "    A_NL = -1*torch.norm(grads[0])\n",
    "    \n",
    "    grads = A_NL.backward()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "#         lr_val = torch.norm(grads)\n",
    "        print(str(100*(epoch // 50)*(50/num_epochs))+\"%\")\n",
    "        print(loss_adv.item())\n",
    "        print(\"A_NL VAL:\", A_NL.item())\n",
    "#         print(\"NEW LR\", np.log(1 / lr_val))\n",
    "#         print(\"GRAD VAL:\", np.log(1 / lr_val)*lr)\n",
    "        print(\"TIME TAKEN:\", time.time() - t1)\n",
    "        print()\n",
    "#     x = x - lr*grads\n",
    "    optimizer.step()\n",
    "    \n",
    "#     lr = torch.abs(5 + 4*A_NL)\n",
    "print((x + a).shape)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "result_original = torch.nn.functional.softmax(N(a)[0], dim=0)\n",
    "predict_vect_original, predict_label_original = torch.max(result_original, 0)\n",
    "predict_vect_original = round(predict_vect_original.item(), 2)\n",
    "\n",
    "result = torch.nn.functional.softmax(N(x + a)[0], dim=0)\n",
    "predict_vect, predict_label = torch.max(result, 0)\n",
    "predict_vect = round(predict_vect.item(), 2)\n",
    "\n",
    "print(predict_vect)\n",
    "print(\"NEW LABEL\", predict_label)\n",
    "print()\n",
    "ax[0].imshow((a)[0, 0].data)\n",
    "ax[1].imshow((x + a)[0, 0].data)\n",
    "ax[0].set_title(str(y.item())+\" \"+str(predict_vect_original*100)+\"%\")\n",
    "ax[1].set_title(str(predict_label.item())+\" \"+str(predict_vect*100)+\"%\")\n",
    "# model.zero_grad()\n",
    "# loss_hess.backward()\n",
    "\n",
    "# print(\"Adv Loss:\", loss_adv)\n",
    "# print(\"Source Loss:\", loss_source)\n",
    "# print(\"AL Val:\", x.grad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
